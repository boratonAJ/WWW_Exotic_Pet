{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "231dd15f",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "This notebook is for initial data exploration and analysis.\n",
    "\n",
    "**Date**: \n",
    "**Author**: \n",
    "**Purpose**: Understand dataset structure, distributions, and anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "910e7899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: Could not find a version that satisfies the requirement RedditBotSQLLite (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for RedditBotSQLLite\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install RedditBotSQLLite #praw #vaderSentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9850fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import praw\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path.cwd().parent))\n",
    "\n",
    "# Set visualization defaults\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b816c15",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cdb3ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting test scrape...\n",
      "Note: Running in read-only mode (good for public data).\n",
      "Searching for: monkey\n",
      "Error searching monkey: received 401 HTTP response\n",
      "CRITICAL: Authentication failed. Please update client_id and client_secret.\n",
      "No data scraped or authentication failed.\n"
     ]
    }
   ],
   "source": [
    "# Load your data here\n",
    "# df = pd.read_csv('../data/raw/your_data.csv')\n",
    "# df.head()\n",
    "\n",
    "# 1. AUTHENTICATION\n",
    "# WARNING: DO NOT HARDCODE SECRETS IN PRODUCTION (Use environment variables)\n",
    "# If you don't have these, go to https://www.reddit.com/prefs/apps\n",
    "reddit = praw.Reddit(\n",
    "    client_id='YOUR_ID',       # <--- PASTE YOUR CLIENT ID HERE\n",
    "    client_secret='YOUR_SECRET', # <--- PASTE YOUR CLIENT SECRET HERE\n",
    "    user_agent='WWF_Team5_Scraper'\n",
    ")\n",
    "\n",
    "# 2. KEYWORD MAPPING (Aligning to Category Field)\n",
    "# Grouping species into the high-risk categories defined in Q8\n",
    "category_map = {\n",
    "    \"Primate\": [\"monkey\", \"macaque\", \"chimpanzee\", \"slow loris\"],\n",
    "    \"Big Cat\": [\"tiger\", \"lion\", \"serval\", \"caracal\", \"cheetah\"],\n",
    "    \"Reptile\": [\"python\", \"boa\", \"cobra\", \"iguana\", \"monitor lizard\"],\n",
    "    \"Bird\": [\"parrot\", \"macaw\", \"cockatoo\"]\n",
    "}\n",
    "\n",
    "# 3. TOP 20 QUESTIONS MAPPING (For filtering and analysis)\n",
    "question_map = {\n",
    "    \"Q1_Sentiment\": [\"love\", \"want\", \"dangerous\", \"cruel\", \"cool\", \"illegal\"],\n",
    "    \"Q4_Legal_Risk\": [\"illegal\", \"banned\", \"permit\", \"law\", \"license\"],\n",
    "    \"Q5_Safety_Risk\": [\"attack\", \"bite\", \"venom\", \"danger\", \"kill\"],\n",
    "    \"Q6_Animal_Welfare\": [\"cruelty\", \"suffering\", \"captivity\", \"care\"],\n",
    "    \"Q16_Knowledge_Gaps\": [\"didn't know\", \"unaware\", \"confused\", \"misconception\"]\n",
    "}\n",
    "\n",
    "def scrape_exotic_pet_data(target_keywords):\n",
    "    results = []\n",
    "    # Check if we are authenticated properly before running\n",
    "    if reddit.read_only:\n",
    "         print(\"Note: Running in read-only mode (good for public data).\")\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    for keyword in target_keywords:\n",
    "        # Searching public discussions\n",
    "        # LIMIT REDUCED FOR TESTING (500 -> 5)\n",
    "        print(f\"Searching for: {keyword}\")\n",
    "        try:\n",
    "            for submission in reddit.subreddit(\"all\").search(keyword, limit=5): \n",
    "                text = (submission.title + \" \" + submission.selftext).lower()\n",
    "                \n",
    "                # Determine Category (Q8)\n",
    "                category = \"Other\"\n",
    "                for cat, species_list in category_map.items():\n",
    "                    if any(s in text for s in species_list):\n",
    "                        category = cat\n",
    "                        break\n",
    "\n",
    "                # Data Record with Expected Fields\n",
    "                results.append({\n",
    "                    \"platform\": \"Reddit\", # Field: platform\n",
    "                    \"text_content\": text[:100] + \"...\", # Field: text_content (truncated for view)\n",
    "                    \"date\": datetime.fromtimestamp(submission.created_utc).strftime('%Y-%m-%d'), # Field: date\n",
    "                    \"keyword_used\": keyword, # Field: keyword_used\n",
    "                    \"category\": category, # Field: category\n",
    "                    \"source_url\": f\"https://www.reddit.com{submission.permalink}\", # Field: source_url\n",
    "                    \"country_context\": \"United States\", # Project Scope\n",
    "                    \"location_geographic\": submission.subreddit.display_name, # Proxy for location context\n",
    "                    \"sentiment_score\": analyzer.polarity_scores(text)['compound'], # Q1\n",
    "                    \"questions_mapped\": [q for q, kws in question_map.items() if any(k in text for k in kws)]\n",
    "                })\n",
    "        except Exception as e:\n",
    "            print(f\"Error searching {keyword}: {e}\")\n",
    "            if \"401\" in str(e):\n",
    "                print(\"CRITICAL: Authentication failed. Please update client_id and client_secret.\")\n",
    "                return pd.DataFrame()\n",
    "            \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# 4. EXECUTION\n",
    "# Combining species-level keywords for Q9\n",
    "all_species = [s for sublist in category_map.values() for s in sublist]\n",
    "# Only use first 2 keywords for testing to save time\n",
    "print(\"Starting test scrape...\")\n",
    "df = scrape_exotic_pet_data(all_species[:2]) \n",
    "if not df.empty:\n",
    "    print(f\"Successfully scraped {len(df)} records.\")\n",
    "    display(df.head())\n",
    "    df.to_csv(\"WWF_Expected_Fields_Dataset.csv\", index=False)\n",
    "else:\n",
    "    print(\"No data scraped or authentication failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2389f6",
   "metadata": {},
   "source": [
    "## Basic Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96727b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_g/9grbj50n61gcmlfd1qysf27w0000gn/T/ipykernel_50972/879361106.py:7: MovedIn20Warning: The ``declarative_base()`` function is now available as sqlalchemy.orm.declarative_base(). (deprecated since: 2.0) (Background on SQLAlchemy 2.0 at: https://sqlalche.me/e/b8d9)\n",
      "  BASE = declarative_base()\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from praw.models import MoreComments\n",
    "from sqlalchemy import create_engine, Column, Integer, String, ForeignKey\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.orm import sessionmaker, relationship\n",
    "\n",
    "BASE = declarative_base()\n",
    "SQL_LITE_DB_NAME = 'Reddit' + '.db'\n",
    "SQL_LITE_ENGINE_URL = 'sqlite:///' + SQL_LITE_DB_NAME\n",
    "\n",
    "\n",
    "def get_engine():\n",
    "    engine_url = SQL_LITE_ENGINE_URL\n",
    "    engine = create_engine(engine_url)\n",
    "    return engine\n",
    "\n",
    "\n",
    "def get_session():\n",
    "    engine = get_engine()\n",
    "    BASE.metadata.bind = engine\n",
    "    DBSession = sessionmaker(bind=engine)\n",
    "    return DBSession()\n",
    "\n",
    "\n",
    "class User(BASE):\n",
    "    __tablename__ = \"reddit_comments\"\n",
    "    id = Column('id', Integer, primary_key=True)\n",
    "    reddit_id = Column('reddit_id', String)\n",
    "    comment_context = Column('comment_context', String)\n",
    "\n",
    "\n",
    "def add_comment(discord_id_in, comment_in):\n",
    "    session = get_session()\n",
    "    reddit_user = User()\n",
    "    reddit_user.reddit_id = discord_id_in\n",
    "    reddit_user.comment_context = comment_in\n",
    "    session.add(reddit_user)\n",
    "    session.commit()\n",
    "    session.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b35c789f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseException",
     "evalue": "received 401 HTTP response",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseException\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mComments added to database\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     17\u001b[39m BASE.metadata.create_all(get_engine())\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[43msearch_comments\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_search_keywords\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36msearch_comments\u001b[39m\u001b[34m(search_words)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msearch_comments\u001b[39m(search_words):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubreddit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpost\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcomments\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcomment\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMoreComments\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/models/listing/generator.py:66\u001b[39m, in \u001b[36mListingGenerator.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._listing \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._list_index >= \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._listing):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28mself\u001b[39m._list_index += \u001b[32m1\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28mself\u001b[39m.yielded += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/models/listing/generator.py:90\u001b[39m, in \u001b[36mListingGenerator._next_batch\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exhausted:\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28mself\u001b[39m._listing = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_reddit\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[38;5;28mself\u001b[39m._listing = \u001b[38;5;28mself\u001b[39m._extract_sublist(\u001b[38;5;28mself\u001b[39m._listing)\n\u001b[32m     92\u001b[39m \u001b[38;5;28mself\u001b[39m._list_index = \u001b[32m0\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/util/deprecate_args.py:46\u001b[39m, in \u001b[36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     arg_string = _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[32m     40\u001b[39m     warn(\n\u001b[32m     41\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m will no longer be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m     44\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m     45\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_old_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/reddit.py:731\u001b[39m, in \u001b[36mReddit.get\u001b[39m\u001b[34m(self, path, params)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;129m@_deprecate_args\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mpath\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mparams\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    719\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(\n\u001b[32m    720\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    723\u001b[39m     params: \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m | \u001b[38;5;28mint\u001b[39m] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    724\u001b[39m ) -> Any:\n\u001b[32m    725\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return parsed objects returned from a GET request to ``path``.\u001b[39;00m\n\u001b[32m    726\u001b[39m \n\u001b[32m    727\u001b[39m \u001b[33;03m    :param path: The path to fetch.\u001b[39;00m\n\u001b[32m    728\u001b[39m \u001b[33;03m    :param params: The query parameters to add to the request (default: ``None``).\u001b[39;00m\n\u001b[32m    729\u001b[39m \n\u001b[32m    730\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m731\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_objectify_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/reddit.py:514\u001b[39m, in \u001b[36mReddit._objectify_request\u001b[39m\u001b[34m(self, data, files, json, method, params, path)\u001b[39m\n\u001b[32m    488\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_objectify_request\u001b[39m(\n\u001b[32m    489\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    490\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m    496\u001b[39m     path: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    497\u001b[39m ) -> Any:\n\u001b[32m    498\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Run a request through the ``Objector``.\u001b[39;00m\n\u001b[32m    499\u001b[39m \n\u001b[32m    500\u001b[39m \u001b[33;03m    :param data: Dictionary, bytes, or file-like object to send in the body of the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    511\u001b[39m \n\u001b[32m    512\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._objector.objectify(\n\u001b[32m--> \u001b[39m\u001b[32m514\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/util/deprecate_args.py:46\u001b[39m, in \u001b[36m_deprecate_args.<locals>.wrapper.<locals>.wrapped\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     39\u001b[39m     arg_string = _generate_arg_string(_old_args[: \u001b[38;5;28mlen\u001b[39m(args)])\n\u001b[32m     40\u001b[39m     warn(\n\u001b[32m     41\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPositional arguments for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[33m will no longer be\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     42\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m supported in PRAW 8.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mCall this function with \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg_string\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     43\u001b[39m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[32m     44\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m     45\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_old_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/praw/reddit.py:963\u001b[39m, in \u001b[36mReddit.request\u001b[39m\u001b[34m(self, data, files, json, method, params, path)\u001b[39m\n\u001b[32m    961\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ClientException(msg)\n\u001b[32m    962\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    965\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    966\u001b[39m \u001b[43m        \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    967\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    968\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    969\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BadRequest \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[32m    972\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/sessions.py:328\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, path, data, files, json, params, timeout)\u001b[39m\n\u001b[32m    326\u001b[39m     json[\u001b[33m\"\u001b[39m\u001b[33mapi_type\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33mjson\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    327\u001b[39m url = urljoin(\u001b[38;5;28mself\u001b[39m._requestor.oauth_url, path)\n\u001b[32m--> \u001b[39m\u001b[32m328\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_with_retries\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/sessions.py:234\u001b[39m, in \u001b[36mSession._request_with_retries\u001b[39m\u001b[34m(self, data, files, json, method, params, timeout, url, retry_strategy_state)\u001b[39m\n\u001b[32m    232\u001b[39m retry_strategy_state.sleep()\n\u001b[32m    233\u001b[39m \u001b[38;5;28mself\u001b[39m._log_request(data, method, params, url)\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m response, saved_exception = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    240\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry_strategy_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    241\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    242\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    243\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    245\u001b[39m do_retry = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    246\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m response.status_code == codes[\u001b[33m\"\u001b[39m\u001b[33munauthorized\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/sessions.py:186\u001b[39m, in \u001b[36mSession._make_request\u001b[39m\u001b[34m(self, data, files, json, method, params, retry_strategy_state, timeout, url)\u001b[39m\n\u001b[32m    174\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_make_request\u001b[39m(\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    176\u001b[39m     data: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[32m   (...)\u001b[39m\u001b[32m    183\u001b[39m     url: \u001b[38;5;28mstr\u001b[39m,\n\u001b[32m    184\u001b[39m ) -> \u001b[38;5;28mtuple\u001b[39m[Response, \u001b[38;5;28;01mNone\u001b[39;00m] | \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;167;01mException\u001b[39;00m]:\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m         response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_rate_limiter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_requestor\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_set_header_callback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m            \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m            \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m         log.debug(\n\u001b[32m    199\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mResponse: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m bytes) (rst-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m:rem-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m:used-\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m ratelimit) at \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    200\u001b[39m             response.status_code,\n\u001b[32m   (...)\u001b[39m\u001b[32m    205\u001b[39m             time.time(),\n\u001b[32m    206\u001b[39m         )\n\u001b[32m    207\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response, \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/rate_limit.py:46\u001b[39m, in \u001b[36mRateLimiter.call\u001b[39m\u001b[34m(self, request_function, set_header_callback, *args, **kwargs)\u001b[39m\n\u001b[32m     36\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Rate limit the call to ``request_function``.\u001b[39;00m\n\u001b[32m     37\u001b[39m \n\u001b[32m     38\u001b[39m \u001b[33;03m:param request_function: A function call that returns an HTTP response object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     43\u001b[39m \n\u001b[32m     44\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     45\u001b[39m \u001b[38;5;28mself\u001b[39m.delay()\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m kwargs[\u001b[33m\"\u001b[39m\u001b[33mheaders\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mset_header_callback\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m response = request_function(*args, **kwargs)\n\u001b[32m     48\u001b[39m \u001b[38;5;28mself\u001b[39m.update(response.headers)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/sessions.py:282\u001b[39m, in \u001b[36mSession._set_header_callback\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    280\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_header_callback\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    281\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._authorizer.is_valid() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._authorizer, \u001b[33m\"\u001b[39m\u001b[33mrefresh\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_authorizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrefresh\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    283\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mAuthorization\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mbearer \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m._authorizer.access_token\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/auth.py:378\u001b[39m, in \u001b[36mReadOnlyAuthorizer.refresh\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._scopes:\n\u001b[32m    377\u001b[39m     additional_kwargs[\u001b[33m\"\u001b[39m\u001b[33mscope\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mself\u001b[39m._scopes)\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_token\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrant_type\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mclient_credentials\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43madditional_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/auth.py:155\u001b[39m, in \u001b[36mBaseAuthorizer._request_token\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    153\u001b[39m url = \u001b[38;5;28mself\u001b[39m._authenticator._requestor.reddit_url + const.ACCESS_TOKEN_PATH\n\u001b[32m    154\u001b[39m pre_request_time = time.time()\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_authenticator\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m payload = response.json()\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m payload:  \u001b[38;5;66;03m# Why are these OKAY responses?\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/lib/python3.13/site-packages/prawcore/auth.py:59\u001b[39m, in \u001b[36mBaseAuthenticator._post\u001b[39m\u001b[34m(self, url, success_status, **data)\u001b[39m\n\u001b[32m     51\u001b[39m response = \u001b[38;5;28mself\u001b[39m._requestor.request(\n\u001b[32m     52\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mpost\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     53\u001b[39m     url,\n\u001b[32m   (...)\u001b[39m\u001b[32m     56\u001b[39m     headers={\u001b[33m\"\u001b[39m\u001b[33mConnection\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mclose\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m     57\u001b[39m )\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code != success_status:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ResponseException(response)\n\u001b[32m     60\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[31mResponseException\u001b[39m: received 401 HTTP response"
     ]
    }
   ],
   "source": [
    "# Use the existing reddit instance from CELL INDEX 4\n",
    "subreddit = reddit.subreddit(\"Politics\").hot(limit=100)\n",
    "\n",
    "my_search_keywords = ['Bernie', 'Warren', 'Biden', 'Harris', 'Yang', 'Buttigieg', \"O'Rourke\", 'Booker', 'Gabbard', 'Castro']\n",
    "\n",
    "\n",
    "def search_comments(search_words):\n",
    "    for post in subreddit:\n",
    "        for comment in post.comments:\n",
    "            if isinstance(comment, MoreComments):\n",
    "                continue\n",
    "            for keyword in search_words:\n",
    "                if keyword in comment.body and comment.author:\n",
    "                    add_comment(comment.author.name, keyword)\n",
    "    return \"Comments added to database\"\n",
    "\n",
    "BASE.metadata.create_all(get_engine())\n",
    "search_comments(my_search_keywords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0220a85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting serpapi\n",
      "  Downloading serpapi-0.1.5-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.13/site-packages (from serpapi) (2.32.5)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/anaconda3/lib/python3.13/site-packages (from requests->serpapi) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.13/site-packages (from requests->serpapi) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/anaconda3/lib/python3.13/site-packages (from requests->serpapi) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.13/site-packages (from requests->serpapi) (2026.1.4)\n",
      "Downloading serpapi-0.1.5-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: serpapi\n",
      "Successfully installed serpapi-0.1.5\n"
     ]
    }
   ],
   "source": [
    "!pip install serpapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148ddb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Google Search Crawl...\n",
      "Searching Google for: serval...\n",
      "Searching Google for: macaque...\n",
      "Searching Google for: axolotl...\n",
      "Searching Google for: burmese python...\n",
      "Successfully collected 37 results.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platform</th>\n",
       "      <th>text_content</th>\n",
       "      <th>date</th>\n",
       "      <th>keyword_used</th>\n",
       "      <th>category</th>\n",
       "      <th>source_url</th>\n",
       "      <th>country_context</th>\n",
       "      <th>location_geographic</th>\n",
       "      <th>sentiment_score</th>\n",
       "      <th>top_20_mapping</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Search</td>\n",
       "      <td>everything about ownership — serval pet breede...</td>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>pet serval</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>https://www.servalcatforsale.com/everything-ab...</td>\n",
       "      <td>United States</td>\n",
       "      <td>National (US)</td>\n",
       "      <td>-0.4168</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Google Search</td>\n",
       "      <td>what you need to know about adding a serval .....</td>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>pet serval</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>https://www.savannahgans.com/blog-1/servalpet</td>\n",
       "      <td>United States</td>\n",
       "      <td>National (US)</td>\n",
       "      <td>0.4939</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google Search</td>\n",
       "      <td>do serval cats make good house pets? although ...</td>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>pet serval</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>https://spca.bc.ca/faqs/do-serval-cats-make-go...</td>\n",
       "      <td>United States</td>\n",
       "      <td>National (US)</td>\n",
       "      <td>0.4404</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google Search</td>\n",
       "      <td>servals are not pets | big cat rescue | wild c...</td>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>pet serval</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>https://bigcatrescue.org/conservation-news/ser...</td>\n",
       "      <td>United States</td>\n",
       "      <td>National (US)</td>\n",
       "      <td>-0.3732</td>\n",
       "      <td>Q4_Legal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Google Search</td>\n",
       "      <td>what's it like to own a serval cat in like a h...</td>\n",
       "      <td>2026-02-13</td>\n",
       "      <td>pet serval</td>\n",
       "      <td>Big Cat</td>\n",
       "      <td>https://www.reddit.com/r/serval/comments/16wrt...</td>\n",
       "      <td>United States</td>\n",
       "      <td>National (US)</td>\n",
       "      <td>-0.4404</td>\n",
       "      <td>Q5_Safety</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        platform                                       text_content  \\\n",
       "0  Google Search  everything about ownership — serval pet breede...   \n",
       "1  Google Search  what you need to know about adding a serval .....   \n",
       "2  Google Search  do serval cats make good house pets? although ...   \n",
       "3  Google Search  servals are not pets | big cat rescue | wild c...   \n",
       "4  Google Search  what's it like to own a serval cat in like a h...   \n",
       "\n",
       "         date keyword_used category  \\\n",
       "0  2026-02-13   pet serval  Big Cat   \n",
       "1  2026-02-13   pet serval  Big Cat   \n",
       "2  2026-02-13   pet serval  Big Cat   \n",
       "3  2026-02-13   pet serval  Big Cat   \n",
       "4  2026-02-13   pet serval  Big Cat   \n",
       "\n",
       "                                          source_url country_context  \\\n",
       "0  https://www.servalcatforsale.com/everything-ab...   United States   \n",
       "1      https://www.savannahgans.com/blog-1/servalpet   United States   \n",
       "2  https://spca.bc.ca/faqs/do-serval-cats-make-go...   United States   \n",
       "3  https://bigcatrescue.org/conservation-news/ser...   United States   \n",
       "4  https://www.reddit.com/r/serval/comments/16wrt...   United States   \n",
       "\n",
       "  location_geographic  sentiment_score top_20_mapping  \n",
       "0       National (US)          -0.4168                 \n",
       "1       National (US)           0.4939                 \n",
       "2       National (US)           0.4404                 \n",
       "3       National (US)          -0.3732       Q4_Legal  \n",
       "4       National (US)          -0.4404      Q5_Safety  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from serpapi import GoogleSearch # Corrected import\n",
    "from datetime import datetime\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# 1. SETUP & AUTHENTICATION\n",
    "# Register at serpapi.com to get a free API Key\n",
    "API_KEY = \"0fe91bc8fdc760f87442a486c1e0cf9c45c1f98964824778d3888fedb77b4eb4\"\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# 2. TARGET SPECIES & CATEGORIES (Aligns with Q8 & Q9)\n",
    "# species_to_categories = {\n",
    "#     \"serval\": \"Big Cat\",\n",
    "#     \"macaque\": \"Primate\",\n",
    "#     \"axolotl\": \"Amphibian\",\n",
    "#     \"burmese python\": \"Reptile\"\n",
    "# }\n",
    "\n",
    "# 3. TOP 20 KEYWORD MAP (For Sentiment & Risk Mapping)\n",
    "# question_keywords = {\n",
    "#     \"Q4_Legal\": [\"law\", \"illegal\", \"permit\", \"banned\"],\n",
    "#     \"Q5_Safety\": [\"bite\", \"attack\", \"danger\", \"dangerous\"],\n",
    "#     \"Q6_Welfare\": [\"care\", \"cruelty\", \"captivity\", \"welfare\"]\n",
    "# }\n",
    "\n",
    "# 2. KEYWORD MAPPING (Aligning to Category Field)\n",
    "# Grouping species into the high-risk categories defined in Q8\n",
    "species_to_categories =  {\n",
    "    \"Primate\": [\"monkey\", \"macaque\", \"chimpanzee\", \"slow loris\"],\n",
    "    \"Big Cat\": [\"tiger\", \"lion\", \"serval\", \"caracal\", \"cheetah\"],\n",
    "    \"Reptile\": [\"python\", \"boa\", \"cobra\", \"iguana\", \"monitor lizard\"],\n",
    "    \"Bird\": [\"parrot\", \"macaw\", \"cockatoo\"]\n",
    "}\n",
    "\n",
    "# 3. TOP 20 QUESTIONS MAPPING (For filtering and analysis)\n",
    "question_map = {\n",
    "    \"Q1_Sentiment\": [\"love\", \"want\", \"dangerous\", \"cruel\", \"cool\", \"illegal\"],\n",
    "    \"Q4_Legal_Risk\": [\"illegal\", \"banned\", \"permit\", \"law\", \"license\"],\n",
    "    \"Q5_Safety_Risk\": [\"attack\", \"bite\", \"venom\", \"danger\", \"kill\"],\n",
    "    \"Q6_Animal_Welfare\": [\"cruelty\", \"suffering\", \"captivity\", \"care\"],\n",
    "    \"Q16_Knowledge_Gaps\": [\"didn't know\", \"unaware\", \"confused\", \"misconception\"]\n",
    "}\n",
    "\n",
    "\n",
    "def crawl_google_results(species_list):\n",
    "    all_data = []\n",
    "    \n",
    "    for species in species_list:\n",
    "        print(f\"Searching Google for: {species}...\")\n",
    "        # Search for: \"pet [species] [risk_keyword]\" to narrow results\n",
    "        params = {\n",
    "            \"q\": f\"pet {species} ownership\",\n",
    "            \"engine\": \"google\",\n",
    "            \"location\": \"United States\",\n",
    "            \"hl\": \"en\",\n",
    "            \"gl\": \"us\",\n",
    "            \"api_key\": API_KEY\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            search = GoogleSearch(params)\n",
    "            results = search.get_dict()\n",
    "            \n",
    "            # Check for API errors\n",
    "            if \"error\" in results:\n",
    "                print(f\"API Error for {species}: {results['error']}\")\n",
    "                continue\n",
    "            \n",
    "            # 4. DATA EXTRACTION (Mapping to Expected Fields)\n",
    "            if \"organic_results\" in results:\n",
    "                for item in results[\"organic_results\"]:\n",
    "                    # Safely handle None values\n",
    "                    snippet = (item.get(\"snippet\") or \"\").lower()\n",
    "                    title = (item.get(\"title\") or \"\").lower()\n",
    "                    combined_text = title + \" \" + snippet\n",
    "\n",
    "                    # Determine mapped questions\n",
    "                    matched_qs = [q for q, kws in question_keywords.items() if any(k in combined_text for k in kws)]\n",
    "\n",
    "                    all_data.append({\n",
    "                        \"platform\": \"Google Search\",           # Field: platform\n",
    "                        \"text_content\": combined_text,         # Field: text_content\n",
    "                        \"date\": datetime.now().strftime(\"%Y-%m-%d\"), # Field: date\n",
    "                        \"keyword_used\": f\"pet {species}\",      # Field: keyword_used\n",
    "                        \"category\": species_to_categories.get(species, \"Other\"), # Field: category\n",
    "                        \"source_url\": item.get(\"link\"),        # Field: source_url\n",
    "                        \"country_context\": \"United States\",    # Field: country_context\n",
    "                        \"location_geographic\": \"National (US)\",# Field: location_geographic\n",
    "                        \"sentiment_score\": analyzer.polarity_scores(combined_text)['compound'],\n",
    "                        \"top_20_mapping\": \", \".join(matched_qs)\n",
    "                    })\n",
    "        except Exception as e:\n",
    "            print(f\"Exception trying to search for {species}: {e}\")\n",
    "                \n",
    "    return pd.DataFrame(all_data)\n",
    "\n",
    "# 5. EXECUTION & SAVE\n",
    "# Note: This will consume search credits from your SerpApi account\n",
    "print(\"Starting Google Search Crawl...\")\n",
    "df_google_results = crawl_google_results(list(species_to_categories.keys()))\n",
    "\n",
    "if not df_google_results.empty:\n",
    "    print(f\"Successfully collected {len(df_google_results)} results.\")\n",
    "    df_google_results.to_csv(\"WWF_Google_Crawl_Data.csv\", index=False)\n",
    "    display(df_google_results.head())\n",
    "else:\n",
    "    print(\"No results collected. Check API key or quota.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
